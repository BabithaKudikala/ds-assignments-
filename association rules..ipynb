# -*- coding: utf-8 -*-

# Prepare rules for the all the data sets 
# 1) Try different values of support and confidence. Observe the change in number of rules for different support,confidence values
# 2) Change the minimum length in apriori algorithm
# 3) Visulize the obtained rules using different plots 

import pandas as pd
import warnings
warnings.filterwarnings('ignore')

book=pd.read_csv('book.csv')
book

pip install mlxtend

df=pd.get_dummies(book)
df

from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder


frequent_itemsets = apriori(df, min_support = 0.1, use_colnames = True)
frequent_itemsets


rules = association_rules(frequent_itemsets, metric = 'lift', min_threshold = 0.7)
rules


rules.sort_values('lift',ascending= False)
rules[rules.lift>1]
rules[rules.lift<1]
rules[rules.leverage == 0]

frequent_itemset = apriori(df,min_support = 0.2, use_colnames = True)
rules = association_rules(frequent_itemset, metric = 'lift', min_threshold = 0.9)
rules


frequent_itemset = apriori(df, min_support = 0.03, use_colnames = True)
rules = association_rules(frequent_itemset, metric = 'lift', min_threshold = 0.6)
rules

import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')

frequent_itemset = apriori(df, min_support = 0.23, use_colnames = True)
rules = association_rules(frequent_itemset, metric = 'lift', min_threshold = 0.7)
rules

import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')

frequent_itemset = apriori(df, min_support = 0.13, use_colnames = True)
rules = association_rules(frequent_itemset, metric = 'lift', min_threshold = 0.6)
rules


import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')


frequent_itemset1 = apriori(df, min_support = 0.05, use_colnames = True)
rules = association_rules(frequent_itemset1, metric = 'lift', min_threshold = 0.9)
rules


import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')


#===========================================================================


# 2) 

movies = pd.read_csv('my_movies.csv')
movies

movies.shape

movies.describe()

movies.corr()

movies.info()

df = movies.iloc[:,5:]
df

frequent_itemset = apriori(df, min_support = 0.02, use_colnames = True)
frequent_itemset

rules = association_rules(frequent_itemset, metric = 'lift', min_threshold = 0.7)
rules

plt.scatter(rules.support, rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')

frequent_itemset = apriori(df, min_support = 0.05, use_colnames = True)
frequent_itemset

rules = association_rules(frequent_itemset, metric ='lift', min_threshold = 0.9)
rules

import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')

frequent_itemset1 = apriori(df, min_support = 0.1, use_colnames = True)
frequent_itemset1

rules = association_rules(frequent_itemset1, metric = 'lift', min_threshold = 0.95)
rules

import matplotlib.pyplot as plt
plt.scatter(rules.support,rules.confidence)
plt.xlabel('Support')
plt.ylabel('Confidence')


































