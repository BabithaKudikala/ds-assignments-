# -*- coding: utf-8 -*-

#1
'''Perform Clustering(Hierarchical, Kmeans & DBSCAN) for the crime data and identify the number of clusters formed and draw inferences.

Data Description:
Murder -- Muder rates in different places of United States
Assualt- Assualt rate in different places of United States
UrbanPop - urban population in different places of United States
Rape - Rape rate in different places of United States'''



import pandas as pd
import warnings
warnings.filterwarnings('ignore')


df=pd.read_csv('crime_data.csv',delimiter=',')
df

df.head()


from sklearn.preprocessing import LabelEncoder
LE=LabelEncoder()
df['Unnamed: 0']=LE.fit_transform(df['Unnamed: 0'])

X=df.iloc[:,0:5].values
X.shape

get_ipython().run_line_magic('matplotlib', 'qt')
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(16,9)


from mpl_toolkits.mplot3d import Axes3D

fig1=plt.figure()
ax=Axes3D(fig1)
ax.scatter(X[:,0],X[:,1],X[:,2])
plt.show()


fig2=plt.figure()
ax=Axes3D(fig2)
ax.scatter(X[:,0],X[:,3],X[:,4])
plt.show()


from sklearn.cluster import AgglomerativeClustering

cluster1=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='single')
Y1=cluster1.fit_predict(X)
Y_new1=pd.DataFrame(Y1)
Y_new1[0].value_counts()

plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,1],c=cluster.labels_,cmap='rainbow')


cluster2=AgglomerativeClustering(n_clusters=6,affinity='euclidean',linkage='ward')
Y2=cluster2.fit_predict(X)
Y_new2=pd.DataFrame(Y2)
Y_new2[0].value_counts()

plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,1],c=cluster2.labels_,cmap='rainbow')


cluster3=AgglomerativeClustering(n_clusters=6,affinity='euclidean',linkage='average')
Y3=cluster3.fit_predict(X)
Y_new3=pd.DataFrame(Y3)
Y_new3[0].value_counts()


plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,2],c=cluster3.labels_,cmap='rainbow')


cluster4=AgglomerativeClustering(n_clusters=7,affinity='euclidean',linkage='complete')
Y4=cluster4.fit_predict(X)
Y_new4=pd.DataFrame(Y4)
Y_new4[0].value_counts()

plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,2],c=cluster4.labels_,cmap='rainbow')


cluster5=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='complete')
Y5=cluster5.fit_predict(X)
Y_new5=pd.DataFrame(Y5)
Y_new5[0].value_counts()


plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,3],c=cluster5.labels_,cmap='rainbow')


cluster6=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='single')
Y6=cluster6.fit_predict(X)
Y_new6=pd.DataFrame(Y6)
Y_new6[0].value_counts()


plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,3],c=cluster6.labels_,cmap='rainbow')


cluster7=AgglomerativeClustering(n_clusters=6,affinity='euclidean',linkage='ward')
Y7=cluster7.fit_predict(X)
Y_new7=pd.DataFrame(Y7)
Y_new7[0].value_counts()


plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,4],c=cluster7.labels_,cmap='rainbow')

cluster8=AgglomerativeClustering(n_clusters=7,affinity='euclidean',linkage='average')
Y8=cluster8.fit_predict(X)
Y_new8=pd.DataFrame(Y8)
Y_new8[0].value_counts()


plt.figure(figsize=(10,7))
plt.scatter(X[:,0],X[:,4],c=cluster7.labels_,cmap='rainbow')

Y_clust1=pd.DataFrame(Y1)
Y_clust1[0].value_counts()


Y_clust2=pd.DataFrame(Y2)
Y_clust2[0].value_counts()


Y_clust3=pd.DataFrame(Y3)
Y_clust3[0].value_counts()


Y_clust3=pd.DataFrame(Y3)
Y_clust3[0].value_counts()


Y_clust4=pd.DataFrame(Y4)
Y_clust4[0].value_counts()


Y_clust5=pd.DataFrame(Y5)
Y_clust5[0].value_counts()


Y_clust6=pd.DataFrame(Y6)
Y_clust6[0].value_counts()


Y_clust7=pd.DataFrame(Y7)
Y_clust7[0].value_counts()

Y_clust8=pd.DataFrame(Y8)
Y_clust8[0].value_counts()


from sklearn.cluster import KMeans

l1=[]
for i in range(1,15):
    kmeans=KMeans(n_clusters=i)
    kmeans=kmeans.fit(X)
    l1.append(kmeans.inertia_)
print(l1)

import matplotlib.pyplot as plt

plt.scatter(range(1,15),l1)
plt.plot(range(1,15),l1,color='red')
plt.show()


from sklearn.preprocessing import StandardScaler

SS=StandardScaler()
SS_X=SS.fit_transform(X)
SS_X

from sklearn.cluster import DBSCAN

dbscan=DBSCAN(eps=1,min_samples=3)
dbscan.fit(SS_X)

Y1=dbscan.labels_
Y_new1=pd.DataFrame(Y1)
Y_new1[0].value_counts()

df1=pd.concat([df,Y_new1],axis=1)
df1

df1[df1[0]==-1]


df_new1=df1[df1[0]!=-1]
df_new1.shape

Y2=dbscan.labels_
Y_new2=pd.DataFrame(Y2)
Y_new2[0].value_counts()

df2=pd.concat([df,Y_new2],axis=1)
df2

df2[df2[0]==-1]

df_new2=df2[df2[0]!=-1]
df_new2.shape

Y3=dbscan.labels_
Y_new3=pd.DataFrame(Y3)
Y_new3[0].value_counts()

df3=pd.concat([df,Y_new3],axis=1)
df3

df3[df3[0]==-1]

df_new3=df3[df3[0]!=-1]
df_new3.shape

Y4=dbscan.labels_
Y_new4=pd.DataFrame(Y4)
Y_new4[0].value_counts()

df4=pd.concat([df,Y_new4],axis=1)
df4

df4[df4[0]==-1]

df_new4=df4[df4[0]!=-1]
df_new4.shape

Y5=dbscan.labels_
Y_new5=pd.DataFrame(Y5)
Y_new5[0].value_counts()

df5=pd.concat([df,Y_new5],axis=1)
df5

df5[df5[0]==-1]

df_new5=df5[df5[0]!=-1]
df_new5.shape

Y6=dbscan.labels_
Y_new6=pd.DataFrame(Y6)
Y_new6[0].value_counts()

df6=pd.concat([df,Y_new6],axis=1)
df6

df6[df6[0]==-1]

df_new6=df6[df6[0]!=-1]
df_new6.shape

Y7=dbscan.labels_
Y_new7=pd.DataFrame(Y7)
Y_new7[0].value_counts()

df7=pd.concat([df,Y_new7],axis=1)
df7

df7[df7[0]==-1]

df_new7=df7[df7[0]!=-1]
df_new7.shape

Y8=dbscan.labels_
Y_new8=pd.DataFrame(Y8)
Y_new8[0].value_counts()

df8=pd.concat([df,Y_new8],axis=1)
df8

df8[df8[0]==-1]

df_new8=df8[df8[0]!=-1]
df_new8.shape

#=========================================================================


































